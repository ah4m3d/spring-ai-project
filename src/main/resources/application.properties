# Ollama endpoint configuration
spring.ai.ollama.chat.options.model=llama3
spring.main.banner-mode=console
logging.level.org.springframework=INFO
logging.level.org.springframework.boot.context.config=DEBUG